
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>CV Exercise 1 - Introduction to Matlab and Edge Detection</title><meta name="generator" content="MATLAB 9.1"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2016-10-07"><meta name="DC.source" content="exercise1.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>CV Exercise 1 - Introduction to Matlab and Edge Detection</h1><!--introduction--><p>
Cole MacLean and Suren Oganesian
</br>
October 10, 2016
</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Lab 1-1 Image Swap</a></li><li><a href="#2">Lab 1-4 Image Split</a></li><li><a href="#3">Lab 1-6 Image Fusing</a></li><li><a href="#4">Lab 2-1 Image Edge Detection</a></li><li><a href="#5">2-1 Discussion</a></li></ul></div><h2 id="1">Lab 1-1 Image Swap</h2><pre class="codeinput"><span class="comment">%create black and white squares to use in producing box patterns</span>
blackbox = zeros(500,500);
whitebox = ones(500,500);

<span class="comment">%color channels are created by stacking black and whiteboxes in appropriate</span>
<span class="comment">%order</span>
channel1 = [blackbox,whitebox;blackbox,whitebox];
channel2 = [blackbox,blackbox;whitebox,whitebox];
channel3 = [whitebox,blackbox;blackbox,blackbox];
<span class="comment">%combine channels into 3-D RGB array</span>
color = cat(3, channel1, channel2, channel3);
imshow(color)
</pre><img vspace="5" hspace="5" src="exercise1_01.png" style="width:547px;height:486px;" alt=""> <h2 id="2">Lab 1-4 Image Split</h2><pre class="codeinput">clooney = imread(<span class="string">'lab1/images/clooney.jpg'</span>);
<span class="comment">%image_swap is a defined function that swaps the left and right image</span>
<span class="comment">%parts after the user inputted split column (214 in this case)</span>
imshow(image_swap(clooney,214))
</pre><img vspace="5" hspace="5" src="exercise1_02.png" style="width:318px;height:186px;" alt=""> <h2 id="3">Lab 1-6 Image Fusing</h2><pre class="codeinput"><span class="comment">%Given 2 images, overlap the first's foreground ontop of the second</span>
hand = imread(<span class="string">'lab1/images/hand.jpg'</span>);
building = imread(<span class="string">'lab1/images/mapfre.jpg'</span>);
buildR = building(:,:,1);
buildG = building(:,:,2);
buildB = building(:,:,3);
handR = hand(:,:,1);
handG = hand(:,:,2);
handB = hand(:,:,3);
bin_hand = im2bw(hand,0.1);
bw_pxs = bin_hand == 1;
buildR(bw_pxs) = handR(bw_pxs);
buildG(bw_pxs) = handG(bw_pxs);
buildB(bw_pxs) = handB(bw_pxs);
fuse = cat(3,buildR,buildG,buildB);
imshow(fuse)
</pre><img vspace="5" hspace="5" src="exercise1_03.png" style="width:352px;height:291px;" alt=""> <h2 id="4">Lab 2-1 Image Edge Detection</h2><pre class="codeinput"><span class="comment">%Comparing Edge Detection Algorithms</span>
<span class="comment">%load testing images</span>
color_starbucks = imread(<span class="string">'lab2/images_video/starbuck.jpg'</span>);
starbucks = rgb2gray(color_starbucks);
dolphin = rgb2gray(imread(<span class="string">'lab2/images_video/doulphin.jpg'</span>));
dog = rgb2gray(imread(<span class="string">'lab2/images_video/dog.jpg'</span>));
fabulous = rgb2gray(imread(<span class="string">'lab2/images_video/fabulous.jpg'</span>));

<span class="comment">%edge detect function takes image an using various detection images to view</span>
<span class="comment">%possible edges</span>
edge_detect(starbucks);
best_edge = edge(starbucks,<span class="string">'Prewitt'</span>,0.1);
<span class="comment">%overlap function takes original image, the edges and which color channel</span>
<span class="comment">%to use as edge enhancement (1 - R, 2- G, 3 - B)</span>
imshow(overlap_edge(color_starbucks,best_edge,1))
snapnow;
<span class="comment">%test best edge detetor parameters on other images</span>
imshow(edge(dolphin,<span class="string">'Prewitt'</span>,0.1))
snapnow;
imshow(edge(dog,<span class="string">'Prewitt'</span>,0.1))
snapnow;
imshow(edge(fabulous,<span class="string">'Prewitt'</span>,0.1))
snapnow;
</pre><img vspace="5" hspace="5" src="exercise1_04.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_05.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_06.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_07.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_08.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_09.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_10.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_11.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_12.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_13.png" style="width:236px;height:177px;" alt=""> <img vspace="5" hspace="5" src="exercise1_14.png" style="width:547px;height:353px;" alt=""> <img vspace="5" hspace="5" src="exercise1_15.png" style="width:318px;height:214px;" alt=""> <img vspace="5" hspace="5" src="exercise1_16.png" style="width:318px;height:214px;" alt=""> <h2 id="5">2-1 Discussion</h2><p>The above images display various edge detection algorithms and different parameters for each algorithm to test which algorithm and parameters work best for detecting the edges of the starbucks logo. 2 detectors stand out as being very good at detecting the edges. These are the Sobel and Prewitt edge detectors, with thresholds both set to 0.1. The Prewitt detector just edges out (Ha!) the Sobel detector, with the detected edges being slightly crisper and more complete then the Sobel, making it the optimized detector. Sobel and Prewitt detectors with higher thresholds performed poorly in detecting edges, and the zerocross edge detector was completely unable to detect edges at any threshold level. This optimal edge detector was then used on 3 other images, to varying degrees of success. It was able to capture the very detailed edges of the fabulous image, but performed poorly in accuractely outlining both the dolphin and dog images.</p><div><ol><li>We used 3 detector algorithms for edge detection - Sobel, Prewitt and zerocross</li><li>For the starbucks image, the best edge detector was Prewitt thresholded at 0.1</li><li>Optimal parameter was threshold at 0.1</li><li>Advantages of this edge detector on other images is that it is very good at obtaining the detailed edges in intricate images like fabulous, but a disadvantage is that it can cause noise as seen in the dolphin image where the water bubbles are captured as edges</li><li>To correct for the noisey edge detection that this detector creates, the parameters could be changed to optimize for each individual image. This is obviously a tedious task, and a comprimise between accuracy across an image corpus is likely needed.</li></ol></div><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2016b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% CV Exercise 1 - Introduction to Matlab and Edge Detection
%
% <html>
% Cole MacLean and Suren Oganesian 
% </br>
% October 10, 2016
% </html>
%
%% Lab 1-1 Image Swap
%create black and white squares to use in producing box patterns
blackbox = zeros(500,500); 
whitebox = ones(500,500);

%color channels are created by stacking black and whiteboxes in appropriate
%order
channel1 = [blackbox,whitebox;blackbox,whitebox];
channel2 = [blackbox,blackbox;whitebox,whitebox];
channel3 = [whitebox,blackbox;blackbox,blackbox];
%combine channels into 3-D RGB array
color = cat(3, channel1, channel2, channel3);
imshow(color)
%% Lab 1-4 Image Split
clooney = imread('lab1/images/clooney.jpg');
%image_swap is a defined function that swaps the left and right image
%parts after the user inputted split column (214 in this case)
imshow(image_swap(clooney,214))
%% Lab 1-6 Image Fusing
%Given 2 images, overlap the first's foreground ontop of the second
hand = imread('lab1/images/hand.jpg');
building = imread('lab1/images/mapfre.jpg');
buildR = building(:,:,1);
buildG = building(:,:,2);
buildB = building(:,:,3);
handR = hand(:,:,1);
handG = hand(:,:,2);
handB = hand(:,:,3);
bin_hand = im2bw(hand,0.1);
bw_pxs = bin_hand == 1;
buildR(bw_pxs) = handR(bw_pxs);
buildG(bw_pxs) = handG(bw_pxs);
buildB(bw_pxs) = handB(bw_pxs);
fuse = cat(3,buildR,buildG,buildB);
imshow(fuse)
%% Lab 2-1 Image Edge Detection 
%Comparing Edge Detection Algorithms
%load testing images
color_starbucks = imread('lab2/images_video/starbuck.jpg');
starbucks = rgb2gray(color_starbucks);
dolphin = rgb2gray(imread('lab2/images_video/doulphin.jpg'));
dog = rgb2gray(imread('lab2/images_video/dog.jpg'));
fabulous = rgb2gray(imread('lab2/images_video/fabulous.jpg'));

%edge detect function takes image an using various detection images to view
%possible edges
edge_detect(starbucks);
best_edge = edge(starbucks,'Prewitt',0.1);
%overlap function takes original image, the edges and which color channel
%to use as edge enhancement (1 - R, 2- G, 3 - B)
imshow(overlap_edge(color_starbucks,best_edge,1))
snapnow;
%test best edge detetor parameters on other images
imshow(edge(dolphin,'Prewitt',0.1))
snapnow;
imshow(edge(dog,'Prewitt',0.1))
snapnow;
imshow(edge(fabulous,'Prewitt',0.1))
snapnow;
%% 2-1 Discussion
% The above images display various edge detection algorithms and different
% parameters for each algorithm to test which algorithm and parameters work
% best for detecting the edges of the starbucks logo. 2 detectors stand out
% as being very good at detecting the edges. These are the Sobel and
% Prewitt edge detectors, with thresholds both set to 0.1. The Prewitt
% detector just edges out (Ha!) the Sobel detector, with the detected edges
% being slightly crisper and more complete then the Sobel, making it the
% optimized detector. Sobel and Prewitt detectors with higher thresholds
% performed poorly in detecting edges, and the zerocross edge detector was
% completely unable to detect edges at any threshold level. This optimal
% edge detector was then used on 3 other images, to varying degrees of
% success. It was able to capture the very detailed edges of the fabulous
% image, but performed poorly in accuractely outlining both the dolphin and
% dog images. 
%
% # We used 3 detector algorithms for edge detection - Sobel, Prewitt and
% zerocross
% # For the starbucks image, the best edge detector was Prewitt thresholded
% at 0.1
% # Optimal parameter was threshold at 0.1
% # Advantages of this edge detector on other images is that it is very
% good at obtaining the detailed edges in intricate images like fabulous,
% but a disadvantage is that it can cause noise as seen in the dolphin
% image where the water bubbles are captured as edges
% # To correct for the noisey edge detection that this detector creates,
% the parameters could be changed to optimize for each individual image.
% This is obviously a tedious task, and a comprimise between accuracy
% across an image corpus is likely needed.
##### SOURCE END #####
--></body></html>